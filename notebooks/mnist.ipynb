{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from model import MLP\n",
    "from control_variates.optim import SGLD, ScaleAdaSGHMC as H_SA_SGHMC\n",
    "from mnist_utils import load_mnist_dataset\n",
    "from trainer import BNNTrainer\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "import dill as pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "input_dim = 784\n",
    "width = 2000\n",
    "depth = 2\n",
    "output_dim = 10\n",
    "lr = 1e-3\n",
    "n_epoch = 100\n",
    "alpha0, beta0 = 10, 10\n",
    "resample_prior_every = 15\n",
    "resample_momentum_every = 50\n",
    "burn_in_epochs = 10\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, valloader = load_mnist_dataset('data', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MLP(input_dim=input_dim, width=width, depth=depth, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = SGLD(model.parameters(), lr=lr, alpha0=alpha0, beta0=beta0)\n",
    "optimizer = H_SA_SGHMC(model.parameters(), lr=lr, alpha0=alpha0, beta0=beta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_func(y_hat, y):\n",
    "    nll = F.cross_entropy(y_hat, y, reduction='sum')\n",
    "    return nll\n",
    "\n",
    "def err_func(y_hat, y):\n",
    "    err = y_hat.argmax(-1).ne(y)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BNNTrainer(model, optimizer, nll_func, err_func, trainloader, valloader, device=device, \n",
    "    resample_prior_every=resample_prior_every,\n",
    "    resample_momentum_every=resample_momentum_every\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2020-08-14 09:14:56,293 Epoch 0 finished. Val loss 2.342348337173462, Val error 0.8652\n2020-08-14 09:15:10,192 Epoch 1 finished. Val loss 2.3883721828460693, Val error 0.9114\n2020-08-14 09:15:25,181 Epoch 2 finished. Val loss 2.2896759510040283, Val error 0.8449\n"
    }
   ],
   "source": [
    "trainer.train(n_epoch=n_epoch, burn_in_epochs=burn_in_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_with_priors = trainer.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_set = trainer.weight_set_samples\n",
    "pickle.dump(weights_set, Path('weights.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_dict_to_vec(state_dict):\n",
    "    return torch.cat([w_i.view(-1) for w_i in state_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezed_weights = [state_dict_to_vec(w) for w in weights_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(x, model):\n",
    "    return F.softmax(model(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binnary_prediction(x, model, classes):\n",
    "    assert len(classes) == 2\n",
    "    return F.softmax(model(x)[..., classes], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [MLP(input_dim=input_dim, width=width, depth=depth, output_dim=output_dim) for w in weights_set]\n",
    "for w, model in zip(weights_set, models):\n",
    "    model.load_state_dict(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mc_estimate(function: callable, models, x: torch.tensor):\n",
    "    res = 0.0\n",
    "    for model in models:\n",
    "        res += function(x, model)\n",
    "    return res / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_naive_variance(function:callable, control_variate: callable, models, x: torch.tensor):\n",
    "    return torch.sum(torch.tensor([(function(x, model) - control_variate(x, model))**2 for model in models])) / (len(models) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stein_control_variate(phi_function, x, y, model):\n",
    "    log_likelihood = compute_log_likelihood(x, y, model)\n",
    "    log_likelihood.backward()\n",
    "    weight = state_dict_to_vec(model.state_dict())\n",
    "    phi_weigth = phi_function(weight, x)\n",
    "    phi_weight.backward()\n",
    "    \n",
    "    control_variate = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(x, y, model):\n",
    "    assert len(classes) = 2\n",
    "    y_hat = model(x)\n",
    "    log_likelihood = -F.cross_entropy(y_hat, y, reduction='sum')\n",
    "\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LinearPhi(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def forward(self, weights, x):\n",
    "        return  self.layer(weights)\n",
    "\n",
    "class BottleneckPhi(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, depth=2):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer_2 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "\n",
    "    def forward(self, weights, x):\n",
    "        return  self.layer(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_linear = LinearPhi(squeezed_weights[0].shape[0])\n",
    "\n",
    "phi_linear.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = phi_linear(squeezed_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  }
 ]
}