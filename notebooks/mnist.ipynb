{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from control_variates.model import MLP\n",
    "from control_variates.optim import LangevinSGD as SGLD, ScaleAdaSGHMC as H_SA_SGHMC\n",
    "from mnist_utils import load_mnist_dataset\n",
    "from control_variates.trainer import BNNTrainer\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "import dill as pickle\n",
    "from pathlib import Path\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "input_dim = 784\n",
    "width = 100\n",
    "depth = 2\n",
    "output_dim = 2\n",
    "lr = 1e-3\n",
    "n_epoch = 200\n",
    "alpha0, beta0 = 10, 10\n",
    "resample_prior_every = 15\n",
    "resample_momentum_every = 50\n",
    "burn_in_epochs = 20\n",
    "save_freq = 2\n",
    "resample_prior_until = 100\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Берем два класса из МНИСТа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Path('../data', 'mnist').mkdir(exist_ok=True, parents=True)\n",
    "trainloader, valloader = load_mnist_dataset(Path('../data', 'mnist'), batch_size, [6, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = MLP(input_dim=input_dim, width=width, depth=depth, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from control_variates.model import LogRegression\n",
    "model = LogRegression(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGLD(model.parameters(), lr=lr, alpha0=alpha0, beta0=beta0)\n",
    "#optimizer = H_SA_SGHMC(model.parameters(), lr=lr, alpha0=alpha0, beta0=beta0)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_func(y_hat, y):\n",
    "    nll = F.cross_entropy(y_hat, y, reduction='sum')\n",
    "    return nll\n",
    "\n",
    "def err_func(y_hat, y):\n",
    "    err = y_hat.argmax(-1).ne(y)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BNNTrainer(model, optimizer, nll_func, err_func, trainloader, valloader, device=device, \n",
    "    resample_prior_every=resample_prior_every,\n",
    "    resample_momentum_every=resample_momentum_every,\n",
    "    save_freq=save_freq,\n",
    "    batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-15 00:53:44,409 Epoch 0 finished. Val loss 0.6892860531806946, Val error 0.005592272496187087\n",
      "2020-08-15 00:53:45,326 Epoch 1 finished. Val loss 0.6376884579658508, Val error 0.006100660904931368\n",
      "2020-08-15 00:53:46,223 Epoch 2 finished. Val loss 0.5597677230834961, Val error 0.005592272496187087\n",
      "2020-08-15 00:53:47,121 Epoch 3 finished. Val loss 0.5181558132171631, Val error 0.004575495678698526\n",
      "2020-08-15 00:53:48,017 Epoch 4 finished. Val loss 0.4870304763317108, Val error 0.004575495678698526\n",
      "2020-08-15 00:53:48,898 Epoch 5 finished. Val loss 0.4641351103782654, Val error 0.004575495678698526\n",
      "2020-08-15 00:53:49,784 Epoch 6 finished. Val loss 0.4641956090927124, Val error 0.006100660904931368\n",
      "2020-08-15 00:53:50,673 Epoch 7 finished. Val loss 0.4078866243362427, Val error 0.0035587188612099642\n",
      "2020-08-15 00:53:51,562 Epoch 8 finished. Val loss 0.388039231300354, Val error 0.004067107269954245\n",
      "2020-08-15 00:53:52,453 Epoch 9 finished. Val loss 0.38133251667022705, Val error 0.0035587188612099642\n",
      "2020-08-15 00:53:53,346 Epoch 10 finished. Val loss 0.3636961877346039, Val error 0.0035587188612099642\n",
      "2020-08-15 00:53:54,246 Epoch 11 finished. Val loss 0.3406078517436981, Val error 0.0035587188612099642\n",
      "2020-08-15 00:53:55,138 Epoch 12 finished. Val loss 0.3358040750026703, Val error 0.0035587188612099642\n",
      "2020-08-15 00:53:56,040 Epoch 13 finished. Val loss 0.3273809552192688, Val error 0.003050330452465684\n",
      "2020-08-15 00:53:56,936 Epoch 14 finished. Val loss 0.3059089481830597, Val error 0.0035587188612099642\n",
      "2020-08-15 00:53:57,838 Epoch 15 finished. Val loss 0.298233300447464, Val error 0.0035587188612099642\n",
      "2020-08-15 00:53:58,728 Epoch 16 finished. Val loss 0.3006388545036316, Val error 0.0035587188612099642\n",
      "2020-08-15 00:53:59,619 Epoch 17 finished. Val loss 0.30358660221099854, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:00,658 Epoch 18 finished. Val loss 0.28988155722618103, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:01,578 Epoch 19 finished. Val loss 0.2812155783176422, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:02,493 Epoch 20 finished. Val loss 0.28193995356559753, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:03,398 Epoch 21 finished. Val loss 0.28071674704551697, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:04,298 Epoch 22 finished. Val loss 0.2721761465072632, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:05,188 Epoch 23 finished. Val loss 0.26679903268814087, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:06,080 Epoch 24 finished. Val loss 0.2577345073223114, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:06,980 Epoch 25 finished. Val loss 0.2488497644662857, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:07,877 Epoch 26 finished. Val loss 0.2546265423297882, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:08,772 Epoch 27 finished. Val loss 0.25445303320884705, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:09,659 Epoch 28 finished. Val loss 0.2596205770969391, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:10,588 Epoch 29 finished. Val loss 0.25972867012023926, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:11,496 Epoch 30 finished. Val loss 0.2513921856880188, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:12,387 Epoch 31 finished. Val loss 0.24201709032058716, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:13,327 Epoch 32 finished. Val loss 0.2379583865404129, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:14,350 Epoch 33 finished. Val loss 0.23519514501094818, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:16,090 Epoch 34 finished. Val loss 0.23096443712711334, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:17,348 Epoch 35 finished. Val loss 0.22122979164123535, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:18,822 Epoch 36 finished. Val loss 0.22195447981357574, Val error 0.004067107269954245\n",
      "2020-08-15 00:54:19,934 Epoch 37 finished. Val loss 0.22699975967407227, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:20,835 Epoch 38 finished. Val loss 0.21088936924934387, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:21,728 Epoch 39 finished. Val loss 0.21106602251529694, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:22,621 Epoch 40 finished. Val loss 0.21061143279075623, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:23,582 Epoch 41 finished. Val loss 0.2159191370010376, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:24,504 Epoch 42 finished. Val loss 0.21350595355033875, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:25,394 Epoch 43 finished. Val loss 0.2131430208683014, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:26,286 Epoch 44 finished. Val loss 0.2114468514919281, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:27,185 Epoch 45 finished. Val loss 0.21525637805461884, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:28,090 Epoch 46 finished. Val loss 0.20543530583381653, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:28,981 Epoch 47 finished. Val loss 0.2071058452129364, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:29,886 Epoch 48 finished. Val loss 0.19941747188568115, Val error 0.003050330452465684\n",
      "2020-08-15 00:54:30,794 Epoch 49 finished. Val loss 0.21028929948806763, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:31,672 Epoch 50 finished. Val loss 0.19267119467258453, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:32,568 Epoch 51 finished. Val loss 0.19683465361595154, Val error 0.004067107269954245\n",
      "2020-08-15 00:54:33,473 Epoch 52 finished. Val loss 0.19451020658016205, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:34,367 Epoch 53 finished. Val loss 0.20365139842033386, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:35,247 Epoch 54 finished. Val loss 0.2045537233352661, Val error 0.004067107269954245\n",
      "2020-08-15 00:54:36,137 Epoch 55 finished. Val loss 0.21613599359989166, Val error 0.004067107269954245\n",
      "2020-08-15 00:54:37,025 Epoch 56 finished. Val loss 0.2091653048992157, Val error 0.004067107269954245\n",
      "2020-08-15 00:54:37,933 Epoch 57 finished. Val loss 0.20632842183113098, Val error 0.004067107269954245\n",
      "2020-08-15 00:54:38,834 Epoch 58 finished. Val loss 0.22402465343475342, Val error 0.004067107269954245\n",
      "2020-08-15 00:54:39,738 Epoch 59 finished. Val loss 0.21494825184345245, Val error 0.004067107269954245\n",
      "2020-08-15 00:54:40,631 Epoch 60 finished. Val loss 0.21276432275772095, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:41,525 Epoch 61 finished. Val loss 0.1990879774093628, Val error 0.004575495678698526\n",
      "2020-08-15 00:54:42,415 Epoch 62 finished. Val loss 0.18005256354808807, Val error 0.004067107269954245\n",
      "2020-08-15 00:54:43,308 Epoch 63 finished. Val loss 0.18300306797027588, Val error 0.004067107269954245\n",
      "2020-08-15 00:54:44,204 Epoch 64 finished. Val loss 0.1878785640001297, Val error 0.005083884087442806\n",
      "2020-08-15 00:54:45,087 Epoch 65 finished. Val loss 0.19954732060432434, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:45,978 Epoch 66 finished. Val loss 0.19153617322444916, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:46,876 Epoch 67 finished. Val loss 0.18858671188354492, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:47,782 Epoch 68 finished. Val loss 0.172842875123024, Val error 0.0035587188612099642\n",
      "2020-08-15 00:54:48,702 Epoch 69 finished. Val loss 0.177988663315773, Val error 0.004575495678698526\n",
      "2020-08-15 00:54:49,608 Epoch 70 finished. Val loss 0.1780628114938736, Val error 0.004067107269954245\n",
      "2020-08-15 00:54:50,494 Epoch 71 finished. Val loss 0.18438073992729187, Val error 0.004067107269954245\n",
      "2020-08-15 00:54:51,388 Epoch 72 finished. Val loss 0.18161046504974365, Val error 0.005083884087442806\n",
      "2020-08-15 00:54:52,284 Epoch 73 finished. Val loss 0.18246886134147644, Val error 0.004575495678698526\n",
      "2020-08-15 00:54:53,195 Epoch 74 finished. Val loss 0.18725620210170746, Val error 0.004575495678698526\n",
      "2020-08-15 00:54:54,106 Epoch 75 finished. Val loss 0.19960910081863403, Val error 0.005083884087442806\n",
      "2020-08-15 00:54:55,044 Epoch 76 finished. Val loss 0.18933223187923431, Val error 0.004575495678698526\n",
      "2020-08-15 00:54:55,957 Epoch 77 finished. Val loss 0.18666033446788788, Val error 0.005083884087442806\n",
      "2020-08-15 00:54:56,874 Epoch 78 finished. Val loss 0.1955728530883789, Val error 0.005083884087442806\n",
      "2020-08-15 00:54:57,781 Epoch 79 finished. Val loss 0.1791357696056366, Val error 0.004575495678698526\n",
      "2020-08-15 00:54:58,689 Epoch 80 finished. Val loss 0.18500357866287231, Val error 0.005592272496187087\n",
      "2020-08-15 00:54:59,590 Epoch 81 finished. Val loss 0.19751064479351044, Val error 0.0066090493136756485\n",
      "2020-08-15 00:55:00,488 Epoch 82 finished. Val loss 0.1958441436290741, Val error 0.0066090493136756485\n",
      "2020-08-15 00:55:01,381 Epoch 83 finished. Val loss 0.17467515170574188, Val error 0.005592272496187087\n",
      "2020-08-15 00:55:02,273 Epoch 84 finished. Val loss 0.1816088855266571, Val error 0.0066090493136756485\n",
      "2020-08-15 00:55:03,182 Epoch 85 finished. Val loss 0.19390104711055756, Val error 0.006100660904931368\n",
      "2020-08-15 00:55:04,095 Epoch 86 finished. Val loss 0.20764459669589996, Val error 0.006100660904931368\n",
      "2020-08-15 00:55:05,035 Epoch 87 finished. Val loss 0.20060664415359497, Val error 0.0066090493136756485\n",
      "2020-08-15 00:55:05,929 Epoch 88 finished. Val loss 0.20589467883110046, Val error 0.006100660904931368\n",
      "2020-08-15 00:55:06,826 Epoch 89 finished. Val loss 0.2047482281923294, Val error 0.0066090493136756485\n",
      "2020-08-15 00:55:07,716 Epoch 90 finished. Val loss 0.2146434187889099, Val error 0.0066090493136756485\n",
      "2020-08-15 00:55:08,609 Epoch 91 finished. Val loss 0.20724354684352875, Val error 0.0066090493136756485\n",
      "2020-08-15 00:55:09,515 Epoch 92 finished. Val loss 0.20343628525733948, Val error 0.0071174377224199285\n",
      "2020-08-15 00:55:10,425 Epoch 93 finished. Val loss 0.20027756690979004, Val error 0.0071174377224199285\n",
      "2020-08-15 00:55:11,313 Epoch 94 finished. Val loss 0.19004996120929718, Val error 0.006100660904931368\n",
      "2020-08-15 00:55:12,226 Epoch 95 finished. Val loss 0.20707359910011292, Val error 0.0071174377224199285\n",
      "2020-08-15 00:55:13,118 Epoch 96 finished. Val loss 0.2137598842382431, Val error 0.007625826131164209\n",
      "2020-08-15 00:55:14,018 Epoch 97 finished. Val loss 0.21244987845420837, Val error 0.007625826131164209\n",
      "2020-08-15 00:55:14,920 Epoch 98 finished. Val loss 0.21895936131477356, Val error 0.0071174377224199285\n",
      "2020-08-15 00:55:15,802 Epoch 99 finished. Val loss 0.19002562761306763, Val error 0.007625826131164209\n",
      "2020-08-15 00:55:16,709 Epoch 100 finished. Val loss 0.17520155012607574, Val error 0.0071174377224199285\n",
      "2020-08-15 00:55:17,607 Epoch 101 finished. Val loss 0.18814590573310852, Val error 0.0066090493136756485\n",
      "2020-08-15 00:55:18,500 Epoch 102 finished. Val loss 0.1799592524766922, Val error 0.0071174377224199285\n",
      "2020-08-15 00:55:19,392 Epoch 103 finished. Val loss 0.16465026140213013, Val error 0.004067107269954245\n",
      "2020-08-15 00:55:20,280 Epoch 104 finished. Val loss 0.16202731430530548, Val error 0.006100660904931368\n",
      "2020-08-15 00:55:21,178 Epoch 105 finished. Val loss 0.1574902981519699, Val error 0.004575495678698526\n",
      "2020-08-15 00:55:22,071 Epoch 106 finished. Val loss 0.17400242388248444, Val error 0.006100660904931368\n",
      "2020-08-15 00:55:22,960 Epoch 107 finished. Val loss 0.1791672557592392, Val error 0.005592272496187087\n",
      "2020-08-15 00:55:23,853 Epoch 108 finished. Val loss 0.1891283541917801, Val error 0.005592272496187087\n",
      "2020-08-15 00:55:24,750 Epoch 109 finished. Val loss 0.19591131806373596, Val error 0.0066090493136756485\n",
      "2020-08-15 00:55:25,651 Epoch 110 finished. Val loss 0.19236096739768982, Val error 0.005592272496187087\n",
      "2020-08-15 00:55:26,528 Epoch 111 finished. Val loss 0.19252559542655945, Val error 0.006100660904931368\n",
      "2020-08-15 00:55:27,415 Epoch 112 finished. Val loss 0.19213807582855225, Val error 0.005592272496187087\n",
      "2020-08-15 00:55:28,308 Epoch 113 finished. Val loss 0.20733708143234253, Val error 0.0066090493136756485\n",
      "2020-08-15 00:55:29,197 Epoch 114 finished. Val loss 0.20188605785369873, Val error 0.006100660904931368\n",
      "2020-08-15 00:55:30,168 Epoch 115 finished. Val loss 0.19404788315296173, Val error 0.006100660904931368\n",
      "2020-08-15 00:55:31,113 Epoch 116 finished. Val loss 0.19481486082077026, Val error 0.0066090493136756485\n",
      "2020-08-15 00:55:32,135 Epoch 117 finished. Val loss 0.18143415451049805, Val error 0.005083884087442806\n",
      "2020-08-15 00:55:33,179 Epoch 118 finished. Val loss 0.18832702934741974, Val error 0.0066090493136756485\n",
      "2020-08-15 00:55:34,200 Epoch 119 finished. Val loss 0.15741878747940063, Val error 0.004067107269954245\n",
      "2020-08-15 00:55:35,230 Epoch 120 finished. Val loss 0.1656845510005951, Val error 0.004575495678698526\n",
      "2020-08-15 00:55:36,366 Epoch 121 finished. Val loss 0.16337072849273682, Val error 0.004575495678698526\n",
      "2020-08-15 00:55:37,427 Epoch 122 finished. Val loss 0.16979390382766724, Val error 0.005083884087442806\n",
      "2020-08-15 00:55:38,351 Epoch 123 finished. Val loss 0.172697052359581, Val error 0.005083884087442806\n",
      "2020-08-15 00:55:39,302 Epoch 124 finished. Val loss 0.16812032461166382, Val error 0.005083884087442806\n",
      "2020-08-15 00:55:40,343 Epoch 125 finished. Val loss 0.16266219317913055, Val error 0.004575495678698526\n",
      "2020-08-15 00:55:41,343 Epoch 126 finished. Val loss 0.14467477798461914, Val error 0.004575495678698526\n",
      "2020-08-15 00:55:42,395 Epoch 127 finished. Val loss 0.16589581966400146, Val error 0.005592272496187087\n",
      "2020-08-15 00:55:43,433 Epoch 128 finished. Val loss 0.1622561514377594, Val error 0.005083884087442806\n",
      "2020-08-15 00:55:44,339 Epoch 129 finished. Val loss 0.177243173122406, Val error 0.005083884087442806\n",
      "2020-08-15 00:55:45,314 Epoch 130 finished. Val loss 0.16860167682170868, Val error 0.005083884087442806\n",
      "2020-08-15 00:55:46,249 Epoch 131 finished. Val loss 0.1583283394575119, Val error 0.004067107269954245\n",
      "2020-08-15 00:55:47,207 Epoch 132 finished. Val loss 0.15627115964889526, Val error 0.004575495678698526\n",
      "2020-08-15 00:55:48,176 Epoch 133 finished. Val loss 0.14421789348125458, Val error 0.004575495678698526\n",
      "2020-08-15 00:55:49,103 Epoch 134 finished. Val loss 0.1447705775499344, Val error 0.005083884087442806\n",
      "2020-08-15 00:55:50,051 Epoch 135 finished. Val loss 0.15163308382034302, Val error 0.005083884087442806\n",
      "2020-08-15 00:55:51,045 Epoch 136 finished. Val loss 0.15413184463977814, Val error 0.004575495678698526\n",
      "2020-08-15 00:55:51,988 Epoch 137 finished. Val loss 0.15462034940719604, Val error 0.004067107269954245\n",
      "2020-08-15 00:55:52,972 Epoch 138 finished. Val loss 0.1422709822654724, Val error 0.004575495678698526\n",
      "2020-08-15 00:55:53,922 Epoch 139 finished. Val loss 0.16418853402137756, Val error 0.004575495678698526\n",
      "2020-08-15 00:55:54,930 Epoch 140 finished. Val loss 0.1571478396654129, Val error 0.005083884087442806\n",
      "2020-08-15 00:55:56,010 Epoch 141 finished. Val loss 0.15368300676345825, Val error 0.004067107269954245\n",
      "2020-08-15 00:55:57,024 Epoch 142 finished. Val loss 0.15543150901794434, Val error 0.004575495678698526\n",
      "2020-08-15 00:55:58,014 Epoch 143 finished. Val loss 0.15368685126304626, Val error 0.004067107269954245\n",
      "2020-08-15 00:55:58,924 Epoch 144 finished. Val loss 0.15582285821437836, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:00,130 Epoch 145 finished. Val loss 0.15351617336273193, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:01,081 Epoch 146 finished. Val loss 0.1537688672542572, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:02,305 Epoch 147 finished. Val loss 0.14785228669643402, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:03,350 Epoch 148 finished. Val loss 0.15181989967823029, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:04,279 Epoch 149 finished. Val loss 0.14465244114398956, Val error 0.003050330452465684\n",
      "2020-08-15 00:56:05,184 Epoch 150 finished. Val loss 0.15331003069877625, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:06,080 Epoch 151 finished. Val loss 0.14194385707378387, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:06,981 Epoch 152 finished. Val loss 0.12724143266677856, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:07,884 Epoch 153 finished. Val loss 0.1441262662410736, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:08,787 Epoch 154 finished. Val loss 0.12442689388990402, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:09,678 Epoch 155 finished. Val loss 0.13247150182724, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:10,571 Epoch 156 finished. Val loss 0.12746180593967438, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:11,479 Epoch 157 finished. Val loss 0.14391230046749115, Val error 0.005083884087442806\n",
      "2020-08-15 00:56:12,379 Epoch 158 finished. Val loss 0.1408405900001526, Val error 0.005083884087442806\n",
      "2020-08-15 00:56:13,282 Epoch 159 finished. Val loss 0.12143576145172119, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:14,181 Epoch 160 finished. Val loss 0.11125876009464264, Val error 0.0035587188612099642\n",
      "2020-08-15 00:56:15,071 Epoch 161 finished. Val loss 0.12841305136680603, Val error 0.0035587188612099642\n",
      "2020-08-15 00:56:15,968 Epoch 162 finished. Val loss 0.13113147020339966, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:16,882 Epoch 163 finished. Val loss 0.11338150501251221, Val error 0.003050330452465684\n",
      "2020-08-15 00:56:17,785 Epoch 164 finished. Val loss 0.12033911049365997, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:18,716 Epoch 165 finished. Val loss 0.11354923993349075, Val error 0.003050330452465684\n",
      "2020-08-15 00:56:19,679 Epoch 166 finished. Val loss 0.12447186559438705, Val error 0.0035587188612099642\n",
      "2020-08-15 00:56:20,800 Epoch 167 finished. Val loss 0.13208259642124176, Val error 0.0035587188612099642\n",
      "2020-08-15 00:56:21,857 Epoch 168 finished. Val loss 0.13129477202892303, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:22,870 Epoch 169 finished. Val loss 0.13557253777980804, Val error 0.005083884087442806\n",
      "2020-08-15 00:56:23,789 Epoch 170 finished. Val loss 0.1272042840719223, Val error 0.003050330452465684\n",
      "2020-08-15 00:56:24,721 Epoch 171 finished. Val loss 0.13351821899414062, Val error 0.0035587188612099642\n",
      "2020-08-15 00:56:25,789 Epoch 172 finished. Val loss 0.12971775233745575, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:27,002 Epoch 173 finished. Val loss 0.12823180854320526, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:28,245 Epoch 174 finished. Val loss 0.1492139846086502, Val error 0.005592272496187087\n",
      "2020-08-15 00:56:29,555 Epoch 175 finished. Val loss 0.1143256276845932, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:30,837 Epoch 176 finished. Val loss 0.10970515757799149, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:32,390 Epoch 177 finished. Val loss 0.11905983090400696, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:33,628 Epoch 178 finished. Val loss 0.13813620805740356, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:34,973 Epoch 179 finished. Val loss 0.11524989455938339, Val error 0.005083884087442806\n",
      "2020-08-15 00:56:36,160 Epoch 180 finished. Val loss 0.1177053302526474, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:37,573 Epoch 181 finished. Val loss 0.11726566404104233, Val error 0.005083884087442806\n",
      "2020-08-15 00:56:38,844 Epoch 182 finished. Val loss 0.1389436423778534, Val error 0.005083884087442806\n",
      "2020-08-15 00:56:39,840 Epoch 183 finished. Val loss 0.11600526422262192, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:40,832 Epoch 184 finished. Val loss 0.10449125617742538, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:41,966 Epoch 185 finished. Val loss 0.10868030041456223, Val error 0.005083884087442806\n",
      "2020-08-15 00:56:42,906 Epoch 186 finished. Val loss 0.11032774299383163, Val error 0.005592272496187087\n",
      "2020-08-15 00:56:43,815 Epoch 187 finished. Val loss 0.10237233340740204, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:45,034 Epoch 188 finished. Val loss 0.11021275818347931, Val error 0.004575495678698526\n",
      "2020-08-15 00:56:46,419 Epoch 189 finished. Val loss 0.10947949439287186, Val error 0.005083884087442806\n",
      "2020-08-15 00:56:47,708 Epoch 190 finished. Val loss 0.11079486459493637, Val error 0.005083884087442806\n",
      "2020-08-15 00:56:48,670 Epoch 191 finished. Val loss 0.11918491125106812, Val error 0.005592272496187087\n",
      "2020-08-15 00:56:49,738 Epoch 192 finished. Val loss 0.1272205412387848, Val error 0.005592272496187087\n",
      "2020-08-15 00:56:50,694 Epoch 193 finished. Val loss 0.1364864557981491, Val error 0.005592272496187087\n",
      "2020-08-15 00:56:51,614 Epoch 194 finished. Val loss 0.1361355185508728, Val error 0.005592272496187087\n",
      "2020-08-15 00:56:52,535 Epoch 195 finished. Val loss 0.1388707458972931, Val error 0.005592272496187087\n",
      "2020-08-15 00:56:53,614 Epoch 196 finished. Val loss 0.14526841044425964, Val error 0.005592272496187087\n",
      "2020-08-15 00:56:54,776 Epoch 197 finished. Val loss 0.11907826364040375, Val error 0.004067107269954245\n",
      "2020-08-15 00:56:55,734 Epoch 198 finished. Val loss 0.1298937201499939, Val error 0.005083884087442806\n",
      "2020-08-15 00:56:56,649 Epoch 199 finished. Val loss 0.12040196359157562, Val error 0.005083884087442806\n"
     ]
    }
   ],
   "source": [
    "trainer.train(n_epoch=n_epoch, burn_in_epochs=burn_in_epochs, resample_prior_until=resample_prior_until)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохраняем сэмплы весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "weights_set = trainer.weight_set_samples[-(n_epoch - resample_prior_until) // save_freq:]\n",
    "\n",
    "print(len(weights_set))\n",
    "\n",
    "Path('../saved_samples', 'mnist_weights').mkdir(exist_ok=True, parents=True)\n",
    "pickle.dump(weights_set, Path('../saved_samples', 'mnist_weights', 'weights.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_set = weights_set[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from control_variates.cv_utils import state_dict_to_vec\n",
    "from control_variates.cv_utils import compute_log_likelihood, compute_mc_estimate, compute_naive_variance, compute_tricky_divergence, stein_control_variate\n",
    "from control_variates.model import get_prediction, get_binary_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "squeezed_weights = [state_dict_to_vec(w) for w in weights_set]\n",
    "\n",
    "models = [LogRegression(input_dim)]*len(weights_set)\n",
    "for w, model in zip(weights_set, models):\n",
    "    model.load_state_dict(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_with_priors = trainer.optimizer\n",
    "\n",
    "priors = {}\n",
    "group_params = opt_with_priors.param_groups[0]['params']\n",
    "for (n, _), p in zip(model.named_parameters(), group_params):  \n",
    "    state = opt_with_priors.state[p]  \n",
    "    priors[n] = state['weight_decay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from control_variates.cv import PsyMLP, PsyDoubleMLP, SteinCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "psy_hidden = 150\n",
    "psy_depth1 = 3\n",
    "psy_depth2 = 2\n",
    "n_iter = 1\n",
    "psy_lr = 1e-7\n",
    "psy_input1 = squeezed_weights[0].shape[0]\n",
    "N_train = len(trainloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new, y_new = next(iter(valloader))\n",
    "#x_new = x_new\n",
    "train_x, train_y = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "        0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "        0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фитим на батче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "psy_model = PsyMLP(psy_input1, psy_hidden, psy_depth1)\n",
    "psy_model.to(device)\n",
    "\n",
    "neural_control_variate = SteinCV(psy_model, train_x, train_y, priors, N_train)\n",
    "\n",
    "ncv_optimizer = torch.optim.Adam(psy_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9035.6797]) tensor([0.])\n",
      "tensor([64628.5117]) tensor([0.])\n",
      "tensor([536011.8125]) tensor([0.])\n",
      "tensor([1604206.7500]) tensor([0.])\n",
      "tensor([4717175.]) tensor([0.])\n",
      "tensor([12049512.]) tensor([0.])\n",
      "tensor([25575036.]) tensor([0.])\n",
      "tensor([47943772.]) tensor([0.])\n",
      "tensor([81103184.]) tensor([0.])\n",
      "tensor([1.4376e+08]) tensor([0.])\n",
      "tensor([2.3611e+08]) tensor([0.])\n",
      "tensor([3.7919e+08]) tensor([0.])\n",
      "tensor([5.8015e+08]) tensor([0.])\n",
      "tensor([8.4431e+08]) tensor([0.])\n",
      "tensor([1.2331e+09]) tensor([0.])\n",
      "tensor([1.7539e+09]) tensor([0.])\n",
      "tensor([2.4182e+09]) tensor([0.])\n",
      "tensor([3.2671e+09]) tensor([0.])\n",
      "tensor([4.3580e+09]) tensor([0.])\n",
      "tensor([5.7454e+09]) tensor([0.])\n",
      "tensor([7.5150e+09]) tensor([0.])\n",
      "tensor([9.7118e+09]) tensor([0.])\n",
      "tensor([1.2454e+10]) tensor([0.])\n",
      "tensor([1.5841e+10]) tensor([0.])\n",
      "tensor([2.0003e+10]) tensor([0.])\n",
      "tensor([2.5103e+10]) tensor([0.])\n",
      "tensor([3.1429e+10]) tensor([0.])\n",
      "tensor([3.8911e+10]) tensor([0.])\n",
      "tensor([4.7887e+10]) tensor([0.])\n",
      "tensor([5.8609e+10]) tensor([0.])\n",
      "tensor([7.1359e+10]) tensor([0.])\n",
      "tensor([8.6439e+10]) tensor([0.])\n",
      "tensor([1.0409e+11]) tensor([0.])\n",
      "tensor([1.2481e+11]) tensor([0.])\n",
      "tensor([1.4858e+11]) tensor([0.])\n",
      "tensor([1.7614e+11]) tensor([0.])\n",
      "tensor([2.0810e+11]) tensor([0.])\n",
      "tensor([2.4499e+11]) tensor([0.])\n",
      "tensor([2.8724e+11]) tensor([0.])\n",
      "tensor([3.3565e+11]) tensor([0.])\n",
      "tensor([3.9052e+11]) tensor([0.])\n",
      "tensor([4.5318e+11]) tensor([0.])\n",
      "tensor([5.1947e+11]) tensor([0.])\n",
      "tensor([5.9422e+11]) tensor([0.])\n",
      "tensor([6.7808e+11]) tensor([0.])\n",
      "tensor([7.7262e+11]) tensor([0.])\n",
      "tensor([8.7730e+11]) tensor([0.])\n",
      "tensor([9.9541e+11]) tensor([0.])\n",
      "tensor([1.1165e+12]) tensor([0.])\n",
      "tensor([1.2462e+12]) tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "function_f = lambda model, x: get_binary_prediction(model, x, classes=[0, 1])\n",
    "\n",
    "for it in range(n_iter):\n",
    "    for x in x_new[:50]:\n",
    "        ncv_optimizer.zero_grad()\n",
    "        mc_variance, no_cv_variance = compute_naive_variance(function_f, neural_control_variate, models, x)\n",
    "        print(mc_variance.data, no_cv_variance.data)\n",
    "        mc_variance.backward()\n",
    "        ncv_optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1.0.weight Parameter containing:\n",
      "tensor([[ 0.0227,  0.0327,  0.0079,  ...,  0.0422,  0.0046, -0.0429],\n",
      "        [ 0.0402, -0.0279,  0.0282,  ...,  0.0178,  0.1172, -0.0346],\n",
      "        [ 0.0450, -0.1537,  0.0589,  ...,  0.0482,  0.0731, -0.1426],\n",
      "        ...,\n",
      "        [ 0.0268,  0.0192, -0.0255,  ...,  0.0347,  0.0044, -0.0571],\n",
      "        [ 0.0421, -0.0266, -0.0084,  ...,  0.0345,  0.0288, -0.0010],\n",
      "        [-0.0019,  0.0370,  0.0134,  ...,  0.0454,  0.0290,  0.0124]],\n",
      "       requires_grad=True)\n",
      "block1.0.bias Parameter containing:\n",
      "tensor([-0.0168,  0.0649,  0.0950,  0.0875,  0.0036, -0.0137,  0.0213,  0.0801,\n",
      "         0.0089,  0.0109,  0.0843,  0.0825, -0.0136, -0.0168, -0.0124,  0.0028,\n",
      "         0.0193,  0.1095,  0.1224,  0.0833,  0.1028, -0.0265, -0.0120, -0.0252,\n",
      "        -0.0203,  0.0040,  0.0098, -0.0048,  0.0139,  0.1094,  0.0117,  0.0665,\n",
      "        -0.0173,  0.0013,  0.0055,  0.0881, -0.0131,  0.0795,  0.0249,  0.0944,\n",
      "        -0.0250, -0.0132,  0.0072, -0.0191, -0.0025, -0.0071,  0.0665,  0.0808,\n",
      "         0.0938, -0.0203,  0.0547,  0.1092,  0.0049,  0.0894,  0.0162,  0.1208,\n",
      "         0.0901, -0.0021, -0.0209, -0.0101,  0.0036,  0.1139,  0.0131,  0.0183,\n",
      "         0.0217,  0.0089, -0.0020, -0.0002, -0.0165,  0.0063,  0.0723, -0.0277,\n",
      "         0.0132, -0.0018,  0.0889,  0.0132,  0.0183, -0.0158, -0.0064,  0.0024,\n",
      "         0.0206, -0.0189,  0.0006, -0.0056,  0.0718,  0.0090,  0.0220,  0.0523,\n",
      "        -0.0172,  0.0097, -0.0201,  0.0137,  0.0078,  0.0033, -0.0225, -0.0100,\n",
      "         0.0525, -0.0003,  0.0005,  0.0091, -0.0026,  0.0967, -0.0168,  0.0175,\n",
      "         0.0155,  0.0165, -0.0154, -0.0249,  0.1047,  0.0598,  0.0760, -0.0196,\n",
      "         0.0218,  0.0898,  0.0047,  0.0241, -0.0217, -0.0052,  0.0195,  0.0944,\n",
      "         0.0856,  0.0793, -0.0183, -0.0009,  0.0027,  0.0185, -0.0254,  0.0122,\n",
      "         0.0525,  0.0039, -0.0137,  0.0183, -0.0309, -0.0204, -0.0177,  0.0002,\n",
      "        -0.0086, -0.0080, -0.0118, -0.0024, -0.0182,  0.1070, -0.0156,  0.0008,\n",
      "         0.0139,  0.0671,  0.1361,  0.0068,  0.0170, -0.0176],\n",
      "       requires_grad=True)\n",
      "block1.2.weight Parameter containing:\n",
      "tensor([[-0.1112, -0.0581,  0.0780,  ...,  0.1174, -0.0369,  0.0690],\n",
      "        [ 0.1141,  0.0484,  0.0034,  ...,  0.1088,  0.0075,  0.0929],\n",
      "        [ 0.1371,  0.1521,  0.1448,  ..., -0.0079,  0.1082,  0.0723],\n",
      "        ...,\n",
      "        [ 0.0294, -0.0010, -0.1175,  ...,  0.1157, -0.1037,  0.1114],\n",
      "        [-0.0119,  0.1506,  0.0255,  ..., -0.1379,  0.1407,  0.0526],\n",
      "        [ 0.1384, -0.1151, -0.0496,  ...,  0.1405,  0.0410,  0.1246]],\n",
      "       requires_grad=True)\n",
      "block1.2.bias Parameter containing:\n",
      "tensor([-0.0431,  0.0363,  0.0556, -0.0759,  0.1210, -0.0512,  0.0229,  0.1057,\n",
      "         0.0374,  0.1582, -0.0816,  0.1019,  0.1041,  0.1010, -0.0283, -0.0554,\n",
      "         0.0308,  0.0283,  0.0065,  0.0905, -0.0431,  0.0091,  0.1347, -0.0605,\n",
      "        -0.0744,  0.1142,  0.0959,  0.0602,  0.0560,  0.0243,  0.0543,  0.0300,\n",
      "        -0.0194, -0.0706, -0.0085,  0.0455,  0.0260,  0.0946,  0.0956, -0.0255,\n",
      "        -0.0498,  0.0529,  0.0346, -0.0621, -0.0098,  0.1025, -0.0190, -0.0169,\n",
      "         0.1193,  0.0247,  0.0044, -0.0349,  0.0677,  0.1141,  0.0059,  0.1312,\n",
      "         0.0519,  0.1261, -0.0182,  0.0589,  0.0065,  0.0321,  0.0401,  0.0323,\n",
      "        -0.0173,  0.0909,  0.0872,  0.0738,  0.0340, -0.0043,  0.0838,  0.1400,\n",
      "        -0.0083, -0.0411, -0.0143, -0.0809,  0.1372,  0.0522,  0.1521,  0.1423,\n",
      "         0.0478,  0.0180,  0.1309, -0.0052, -0.0089, -0.0116,  0.0294, -0.0286,\n",
      "         0.0249,  0.0674,  0.0665,  0.0988, -0.0492, -0.0700,  0.0413,  0.0415,\n",
      "        -0.0787, -0.0430, -0.0679,  0.0875, -0.0137,  0.1375, -0.0485,  0.1622,\n",
      "        -0.0330,  0.0718, -0.0076, -0.0239,  0.0301,  0.1002,  0.0621,  0.0058,\n",
      "         0.1449,  0.1067, -0.0215, -0.0469,  0.0610,  0.0517,  0.0980, -0.0145,\n",
      "         0.0704,  0.0033,  0.0466,  0.0393,  0.1566, -0.0437, -0.0639,  0.0968,\n",
      "         0.0530, -0.0794,  0.0120,  0.0630, -0.0813,  0.0343,  0.1200,  0.1452,\n",
      "         0.1518,  0.1197, -0.0112,  0.0492, -0.0224,  0.0341,  0.0725,  0.0237,\n",
      "         0.1508,  0.1504,  0.0212, -0.0334,  0.1475, -0.0374],\n",
      "       requires_grad=True)\n",
      "block1.4.weight Parameter containing:\n",
      "tensor([[ 0.1210, -0.1314, -0.0164,  ..., -0.1346, -0.0298, -0.0540],\n",
      "        [ 0.0143,  0.0355,  0.0421,  ..., -0.0961,  0.0017,  0.1123],\n",
      "        [-0.1023, -0.0939, -0.0198,  ...,  0.0655, -0.0364, -0.0158],\n",
      "        ...,\n",
      "        [-0.0300, -0.0916, -0.1283,  ...,  0.0714,  0.0775, -0.0049],\n",
      "        [-0.0202,  0.0748, -0.1042,  ..., -0.0924,  0.0102,  0.0685],\n",
      "        [ 0.0271, -0.0561,  0.0940,  ..., -0.0836,  0.0061,  0.0645]],\n",
      "       requires_grad=True)\n",
      "block1.4.bias Parameter containing:\n",
      "tensor([ 0.0339,  0.0025, -0.0279,  0.1616,  0.0187, -0.0195, -0.0620,  0.1422,\n",
      "        -0.0264, -0.0832, -0.0530,  0.1065, -0.0777,  0.0266, -0.0072, -0.0195,\n",
      "         0.0627, -0.0395,  0.0876, -0.0081, -0.0376,  0.0510,  0.1577, -0.0659,\n",
      "         0.0713,  0.0480,  0.0031, -0.0252,  0.0455, -0.0355,  0.0033,  0.0280,\n",
      "        -0.0401,  0.0360, -0.0638, -0.0878, -0.0383,  0.0179,  0.1142,  0.1676,\n",
      "         0.0624, -0.0727,  0.0313,  0.0406, -0.0623,  0.0331,  0.0555,  0.1236,\n",
      "        -0.0452,  0.0582, -0.0225,  0.0776,  0.0260,  0.0470, -0.0425,  0.0766,\n",
      "         0.0402,  0.0811,  0.0279,  0.1187,  0.0488,  0.0418,  0.0252, -0.0331,\n",
      "         0.0248, -0.0867,  0.1051,  0.0669,  0.0284,  0.0337,  0.0713,  0.0076,\n",
      "        -0.0527,  0.0741, -0.0716, -0.0452,  0.0688, -0.0106,  0.1601,  0.0252,\n",
      "         0.0405,  0.1677, -0.0516, -0.1054,  0.1180, -0.0429, -0.0582,  0.0150,\n",
      "         0.0667, -0.0509, -0.0831,  0.0173,  0.0009, -0.0804,  0.0432,  0.0452,\n",
      "         0.0721,  0.0024,  0.0290,  0.0527,  0.0985,  0.1441,  0.0587,  0.0792,\n",
      "         0.1531, -0.0206, -0.0424,  0.0268,  0.0778,  0.0190, -0.0559, -0.0314,\n",
      "        -0.0430,  0.0215, -0.0925, -0.0267,  0.0371,  0.0811,  0.0932,  0.0518,\n",
      "         0.1546,  0.1229,  0.0293,  0.1192, -0.0469,  0.0150,  0.0314,  0.1104,\n",
      "        -0.0064,  0.0387, -0.0672,  0.0130, -0.0272, -0.0511,  0.0863,  0.1245,\n",
      "         0.0428,  0.0511,  0.0247,  0.1328, -0.0769, -0.0042,  0.0289, -0.0336,\n",
      "        -0.0567, -0.0596,  0.0407,  0.0430,  0.0601, -0.0781],\n",
      "       requires_grad=True)\n",
      "block2.0.weight Parameter containing:\n",
      "tensor([[-0.1447, -0.1395, -0.1210,  ..., -0.0668, -0.0865, -0.1399],\n",
      "        [-0.0892,  0.0244, -0.0579,  ...,  0.0434, -0.0954,  0.0276],\n",
      "        [-0.0626, -0.1366, -0.0359,  ..., -0.0883,  0.0014, -0.0611],\n",
      "        ...,\n",
      "        [-0.0239,  0.0622, -0.0749,  ...,  0.0002, -0.0112, -0.0441],\n",
      "        [-0.0082, -0.1042, -0.0902,  ...,  0.0012, -0.1402, -0.1167],\n",
      "        [-0.0357, -0.0332, -0.0925,  ..., -0.0115, -0.0302, -0.0250]],\n",
      "       requires_grad=True)\n",
      "block2.0.bias Parameter containing:\n",
      "tensor([ 0.0841,  0.0142,  0.0795, -0.0211,  0.0717,  0.0062, -0.0138,  0.0457,\n",
      "         0.0687,  0.0678,  0.0650,  0.0456, -0.0345, -0.0398,  0.0856,  0.0663,\n",
      "         0.0708,  0.0019,  0.0604, -0.0002,  0.0229,  0.1190,  0.0476,  0.1023,\n",
      "         0.0061, -0.0062,  0.0681,  0.0511,  0.0499,  0.0718,  0.0899,  0.0416,\n",
      "        -0.0394, -0.0004,  0.0898, -0.0077,  0.0648,  0.0713,  0.0976,  0.0015,\n",
      "         0.1054,  0.0586,  0.1031,  0.0881,  0.0048,  0.0624,  0.0973,  0.0509,\n",
      "         0.0229,  0.0705,  0.0229,  0.0973,  0.1081,  0.0173,  0.0680,  0.0913,\n",
      "         0.0956,  0.0139,  0.0901,  0.0879, -0.0402,  0.0538,  0.0582,  0.0369,\n",
      "         0.0236,  0.0775,  0.0029,  0.0597,  0.0456,  0.0933, -0.0060,  0.0905,\n",
      "         0.0494,  0.0470, -0.0278, -0.0198,  0.0792,  0.0058, -0.0178,  0.0807,\n",
      "         0.0613,  0.0742, -0.0235,  0.0553,  0.1046,  0.0718, -0.0066,  0.0039,\n",
      "         0.0829,  0.0810, -0.0367,  0.0497,  0.0513,  0.0206,  0.0250, -0.0340,\n",
      "         0.0850, -0.0024, -0.0154,  0.0749,  0.0092,  0.0367,  0.0750,  0.0669,\n",
      "        -0.0368, -0.0148,  0.0637,  0.0003,  0.0296,  0.0432,  0.0615,  0.0662,\n",
      "         0.0003,  0.0882,  0.0037,  0.0877, -0.0225,  0.1087,  0.0392,  0.0713,\n",
      "         0.0668,  0.0701, -0.0376,  0.0084, -0.0277, -0.0262,  0.0858,  0.0150,\n",
      "         0.0133,  0.0265, -0.0004,  0.0601,  0.1231,  0.1007,  0.0772, -0.0091,\n",
      "        -0.0210,  0.0720,  0.0645, -0.0247,  0.0550,  0.1080, -0.0350,  0.0156,\n",
      "         0.0540,  0.0524,  0.1216,  0.0244,  0.0536,  0.0389],\n",
      "       requires_grad=True)\n",
      "block2.2.weight Parameter containing:\n",
      "tensor([[ 0.0849,  0.0779,  0.0628,  ...,  0.0469, -0.1074, -0.0861],\n",
      "        [-0.1619, -0.0979, -0.0454,  ..., -0.0447, -0.0712, -0.1121],\n",
      "        [-0.0889,  0.0945, -0.0172,  ..., -0.0898,  0.0296,  0.1170],\n",
      "        ...,\n",
      "        [-0.1516, -0.0215, -0.1401,  ...,  0.1211, -0.1104,  0.1129],\n",
      "        [ 0.0262, -0.0269,  0.1779,  ...,  0.1520,  0.2163,  0.0692],\n",
      "        [ 0.0914, -0.1306, -0.0979,  ...,  0.0443, -0.0848, -0.1159]],\n",
      "       requires_grad=True)\n",
      "block2.2.bias Parameter containing:\n",
      "tensor([ 1.0779e-02,  5.4361e-02, -2.1569e-02,  1.6569e-01,  1.1676e-01,\n",
      "         5.9456e-02,  2.8397e-02,  1.5827e-01, -7.9186e-02,  6.3809e-02,\n",
      "         3.6247e-02,  3.2414e-02,  2.1624e-02, -1.3582e-02,  2.9352e-02,\n",
      "         6.2919e-02,  3.8899e-03, -2.1643e-02,  1.2241e-01,  1.9065e-02,\n",
      "        -1.2716e-04,  2.2186e-02,  4.7501e-02,  1.1560e-02,  1.4441e-02,\n",
      "        -5.4913e-02,  1.5371e-01,  4.5790e-02,  1.5161e-01, -4.8085e-02,\n",
      "         5.7746e-02,  1.6012e-01,  5.4581e-02,  1.4377e-02,  1.5584e-01,\n",
      "         2.3838e-02,  2.1441e-02, -2.4637e-02, -4.1967e-02,  8.6926e-02,\n",
      "         2.9931e-02, -2.4681e-02, -2.4550e-03,  8.0439e-02,  6.0904e-02,\n",
      "         3.1936e-02,  4.1833e-02,  1.1341e-01,  1.6566e-01,  1.2384e-01,\n",
      "         1.0441e-01, -7.3884e-02, -5.2056e-02,  1.0599e-01, -4.3220e-02,\n",
      "        -1.8392e-02, -9.1097e-02,  1.6029e-01, -9.3584e-02,  4.7821e-02,\n",
      "         1.5161e-01,  4.0426e-02,  8.1394e-02, -3.0781e-02,  1.5277e-01,\n",
      "         8.9177e-03,  1.0140e-02, -6.0734e-02,  1.4662e-01,  9.9482e-02,\n",
      "         4.9652e-02,  1.2878e-01,  4.9328e-02,  5.9526e-02,  1.5354e-02,\n",
      "         2.4541e-02, -6.1709e-02,  2.1171e-03,  1.3255e-01, -1.1614e-02,\n",
      "         7.2037e-02,  1.1989e-01, -5.9232e-02,  2.5109e-02,  1.0532e-01,\n",
      "         8.6334e-02, -4.1277e-02,  1.2888e-01,  1.5054e-01,  9.2861e-02,\n",
      "         5.7408e-02,  1.3906e-01,  1.8037e-02,  1.4044e-02, -4.8990e-02,\n",
      "         5.2873e-02,  1.9721e-02, -7.3370e-02, -5.2230e-02,  4.4414e-02,\n",
      "         5.8019e-02,  1.1512e-01, -5.2818e-03,  5.0016e-02,  8.9622e-02,\n",
      "         1.0189e-01,  7.9427e-02,  1.2627e-01, -5.2030e-02,  5.8509e-02,\n",
      "        -7.1023e-02,  5.8567e-02, -1.0756e-02, -5.0450e-02, -6.8206e-02,\n",
      "         1.6745e-02,  1.3633e-01,  3.9350e-02,  3.6566e-02,  2.7916e-02,\n",
      "        -7.1462e-02,  1.3327e-01,  1.3193e-01,  1.3640e-01, -6.6606e-02,\n",
      "         4.7982e-02,  5.7718e-02,  4.5662e-02,  5.0012e-02,  3.4557e-02,\n",
      "        -8.9763e-02,  9.5854e-02, -5.3691e-02,  2.3134e-02,  1.0813e-01,\n",
      "         1.5226e-01,  2.8901e-02,  2.6270e-02,  1.2759e-01,  4.4683e-02,\n",
      "        -2.3625e-02,  3.6316e-02,  1.5415e-01,  6.7893e-02,  4.5608e-02,\n",
      "         6.8428e-02,  2.3381e-02, -3.7730e-02,  1.7019e-01, -9.3713e-02],\n",
      "       requires_grad=True)\n",
      "final.weight Parameter containing:\n",
      "tensor([[ 0.0119,  0.0331,  0.0677, -0.1328, -0.2031,  0.1174,  0.0502, -0.1934,\n",
      "          0.0465,  0.0978,  0.0529, -0.2976,  0.0861, -0.0099,  0.1562,  0.1302,\n",
      "          0.0557,  0.1661, -0.1345,  0.1153,  0.0411, -0.2271, -0.2936,  0.0219,\n",
      "         -0.2487, -0.1080, -0.1416,  0.1028, -0.2430,  0.1099, -0.0906, -0.2773,\n",
      "          0.1527, -0.1416, -0.1129,  0.0518,  0.0744,  0.1683, -0.2881, -0.2441,\n",
      "          0.0520, -0.0047,  0.1523, -0.1487,  0.1121, -0.1822, -0.2851, -0.1662,\n",
      "         -0.1190, -0.3041, -0.1374, -0.1361,  0.1162, -0.1770,  0.0993,  0.0583,\n",
      "          0.0885, -0.2971,  0.1071, -0.2566, -0.1567, -0.1000, -0.1925,  0.1852,\n",
      "         -0.1406,  0.0381, -0.0830,  0.0031, -0.2619, -0.2912,  0.0140, -0.1994,\n",
      "          0.1590, -0.2537,  0.1276,  0.1649, -0.1348,  0.1186, -0.2296,  0.0806,\n",
      "          0.0706, -0.1598,  0.1496,  0.1371, -0.1095, -0.1340,  0.1170, -0.2779,\n",
      "         -0.1444, -0.0882,  0.0177, -0.1093,  0.1861,  0.0992,  0.0775,  0.1161,\n",
      "         -0.2702,  0.0321,  0.0950,  0.1764, -0.2958, -0.2598, -0.1495, -0.2865,\n",
      "         -0.1206, -0.0931, -0.1863, -0.1290,  0.0854, -0.1499,  0.1150, -0.1782,\n",
      "          0.0326, -0.1837,  0.1169, -0.0072, -0.1454, -0.2662, -0.1644,  0.1593,\n",
      "         -0.2861, -0.3044, -0.2891, -0.2393,  0.1705,  0.0826,  0.1135, -0.1585,\n",
      "         -0.1709,  0.0535, -0.0031, -0.2321,  0.0147,  0.0518, -0.1412, -0.2045,\n",
      "         -0.1538,  0.1685, -0.2732, -0.1906,  0.1572, -0.2456, -0.1245, -0.1128,\n",
      "          0.1395,  0.1851,  0.1003,  0.0598, -0.2581,  0.0271]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for n, p in psy_model.named_parameters():\n",
    "    print(n, p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
