{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "import dill as pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from utils import DatasetStandarsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/UCI_telescope/magic04.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[:, 10].replace({\"g\": 1, \"h\": 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         0         1       2       3       4         5        6        7   \\\n0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n\n        8         9   10  \n0  40.0920   81.8828   1  \n1   6.3609  205.2610   1  \n2  76.9600  256.7880   1  \n3  10.4490  116.7370   1  \n4   4.6480  356.4620   1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28.7967</td>\n      <td>16.0021</td>\n      <td>2.6449</td>\n      <td>0.3918</td>\n      <td>0.1982</td>\n      <td>27.7004</td>\n      <td>22.0110</td>\n      <td>-8.2027</td>\n      <td>40.0920</td>\n      <td>81.8828</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>31.6036</td>\n      <td>11.7235</td>\n      <td>2.5185</td>\n      <td>0.5303</td>\n      <td>0.3773</td>\n      <td>26.2722</td>\n      <td>23.8238</td>\n      <td>-9.9574</td>\n      <td>6.3609</td>\n      <td>205.2610</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>162.0520</td>\n      <td>136.0310</td>\n      <td>4.0612</td>\n      <td>0.0374</td>\n      <td>0.0187</td>\n      <td>116.7410</td>\n      <td>-64.8580</td>\n      <td>-45.2160</td>\n      <td>76.9600</td>\n      <td>256.7880</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23.8172</td>\n      <td>9.5728</td>\n      <td>2.3385</td>\n      <td>0.6147</td>\n      <td>0.3922</td>\n      <td>27.2107</td>\n      <td>-6.4633</td>\n      <td>-7.1513</td>\n      <td>10.4490</td>\n      <td>116.7370</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>75.1362</td>\n      <td>30.9205</td>\n      <td>3.1611</td>\n      <td>0.3168</td>\n      <td>0.1832</td>\n      <td>-5.5277</td>\n      <td>28.5525</td>\n      <td>21.8393</td>\n      <td>4.6480</td>\n      <td>356.4620</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.asarray(df.loc[:, :9]), np.asarray(df.loc[:, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_test, y_tr, y_test = train_test_split(X, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7949526813880127"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, penalty='l2', C=1./8).fit(x_tr, y_tr)\n",
    "(clf.predict(x_test) == y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = []\n",
    "for x, y in zip(x_tr, y_tr):\n",
    "    tr_dataset.append((torch.tensor(x).float(), torch.tensor(y).long()))\n",
    "\n",
    "test_dataset = []\n",
    "for x, y in zip(x_test, y_test):\n",
    "    test_dataset.append((torch.tensor(x).float(), torch.tensor(y).long()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = DatasetStandarsScaler()\n",
    "scaler.fit(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = scaler.transform(tr_dataset)\n",
    "test_dataset = scaler.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = DatasetStandarsScaler()\n",
    "scaler.fit(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path('../../data/UCI_telescope/tr_dataset.pkl').open('wb') as fp:\n",
    "    pickle.dump(tr_dataset, fp)\n",
    "\n",
    "with Path('../../data/UCI_telescope/test_dataset.pkl').open('wb') as fp:\n",
    "    pickle.dump(test_dataset, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(tr_dataset, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0.2210, -0.1252,  0.3556, -0.8831, -0.8789,  1.0611,  0.6481,  0.5907,\n         -0.9689,  0.3059],\n        [ 0.9572, -0.0591,  1.0591, -0.9749, -1.0200,  1.0628,  1.9190,  0.7679,\n         -0.8906,  0.8168],\n        [ 0.0881, -0.2130,  1.1236, -0.8668, -0.9232,  0.8191,  0.5798, -0.4339,\n         -0.9699,  0.4350]])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/UCI_EEG/dataset.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        0        1        2        3        4        5        6        7   \\\n0  4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n1  4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n2  4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n3  4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n4  4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n\n        8        9        10       11       12       13  14  \n0  4222.05  4238.46  4211.28  4280.51  4635.90  4393.85   0  \n1  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10   0  \n2  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23   0  \n3  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41   0  \n4  4210.77  4244.10  4212.82  4288.21  4632.82  4398.46   0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4329.23</td>\n      <td>4009.23</td>\n      <td>4289.23</td>\n      <td>4148.21</td>\n      <td>4350.26</td>\n      <td>4586.15</td>\n      <td>4096.92</td>\n      <td>4641.03</td>\n      <td>4222.05</td>\n      <td>4238.46</td>\n      <td>4211.28</td>\n      <td>4280.51</td>\n      <td>4635.90</td>\n      <td>4393.85</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4324.62</td>\n      <td>4004.62</td>\n      <td>4293.85</td>\n      <td>4148.72</td>\n      <td>4342.05</td>\n      <td>4586.67</td>\n      <td>4097.44</td>\n      <td>4638.97</td>\n      <td>4210.77</td>\n      <td>4226.67</td>\n      <td>4207.69</td>\n      <td>4279.49</td>\n      <td>4632.82</td>\n      <td>4384.10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4327.69</td>\n      <td>4006.67</td>\n      <td>4295.38</td>\n      <td>4156.41</td>\n      <td>4336.92</td>\n      <td>4583.59</td>\n      <td>4096.92</td>\n      <td>4630.26</td>\n      <td>4207.69</td>\n      <td>4222.05</td>\n      <td>4206.67</td>\n      <td>4282.05</td>\n      <td>4628.72</td>\n      <td>4389.23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4328.72</td>\n      <td>4011.79</td>\n      <td>4296.41</td>\n      <td>4155.90</td>\n      <td>4343.59</td>\n      <td>4582.56</td>\n      <td>4097.44</td>\n      <td>4630.77</td>\n      <td>4217.44</td>\n      <td>4235.38</td>\n      <td>4210.77</td>\n      <td>4287.69</td>\n      <td>4632.31</td>\n      <td>4396.41</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4326.15</td>\n      <td>4011.79</td>\n      <td>4292.31</td>\n      <td>4151.28</td>\n      <td>4347.69</td>\n      <td>4586.67</td>\n      <td>4095.90</td>\n      <td>4627.69</td>\n      <td>4210.77</td>\n      <td>4244.10</td>\n      <td>4212.82</td>\n      <td>4288.21</td>\n      <td>4632.82</td>\n      <td>4398.46</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.asarray(df.loc[:, :13]), np.asarray(df.loc[:, 14])\n",
    "x_tr, x_test, y_tr, y_test = train_test_split(X, Y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = []\n",
    "for x, y in zip(x_tr, y_tr):\n",
    "    tr_dataset.append((torch.tensor(x).float(), torch.tensor(y).long()))\n",
    "\n",
    "test_dataset = []\n",
    "for x, y in zip(x_test, y_test):\n",
    "    test_dataset.append((torch.tensor(x).float(), torch.tensor(y).long()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = DatasetStandarsScaler()\n",
    "scaler.fit(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = scaler.transform(tr_dataset)\n",
    "test_dataset = scaler.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([ 1.7936e-08,  3.1409e-08, -9.6661e-08, -8.7989e-08,  3.9585e-10,\n        -3.7368e-09,  1.2283e-08, -2.2446e-09,  1.2820e-07,  1.1848e-08,\n        -2.4447e-07, -8.9526e-10, -7.0873e-08, -1.9701e-08]) tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n        1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
    }
   ],
   "source": [
    "caler = DatasetStandarsScaler()\n",
    "scaler.fit(tr_dataset)\n",
    "print(scaler.mean, scaler.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path('../../data/UCI_EEG/tr_dataset.pkl').open('wb') as fp:\n",
    "    pickle.dump(tr_dataset, fp)\n",
    "\n",
    "with Path('../../data/UCI_EEG/test_dataset.pkl').open('wb') as fp:\n",
    "    pickle.dump(test_dataset, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(tr_dataset, batch_size=3)\n",
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0.0222,  1.2415,  1.6496,  2.3576,  2.2347,  0.0117,  2.0172,  1.7829,\n          0.0148,  1.7961,  1.3611,  1.5701,  0.0437,  0.0024],\n        [-0.0153, -0.3291, -0.2520, -0.8619, -0.1763, -0.0138, -0.2810, -0.5600,\n         -0.0115, -0.1523, -0.1039, -0.0245,  0.0061, -0.0099],\n        [-0.0186, -0.5037, -0.1482, -0.6254, -0.6133, -0.0112, -0.3112,  0.1311,\n         -0.0102,  0.3723, -0.1613,  0.0574, -0.0151, -0.0111]])"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, penalty='l2', C=1./13).fit(x_tr, y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6350689808633734"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "(clf.predict(x_test) == y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6366135239142386"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "(clf.predict(x_tr) == y_tr).sum() / y_tr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, r):\n",
    "        super().__init__()\n",
    "        self.r=r\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.asarray(df.loc[:, :13]), np.asarray(df.loc[:, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "StandardScaler()"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([4321.91777704, 4009.76769359, 4264.02243258, 4164.94632644,\n       4341.74107543, 4644.02237917, 4110.40015955, 4616.05690387,\n       4218.82661015, 4231.3161996 , 4202.45689987, 4279.23277437,\n       4615.20533556, 4416.43583244])"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([6.21000914e+06, 2.11049637e+03, 1.97372002e+03, 2.72090608e+07,\n       1.20670511e+03, 8.55382278e+06, 2.11671119e+07, 8.57999322e+02,\n       4.56393669e+06, 1.44777454e+03, 1.42768508e+03, 1.72581460e+03,\n       1.46006048e+06, 3.47049225e+07])"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "scaler.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(14980,)"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "X.mean(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centr = X - X.mean(0)\n",
    "covariance = (X_centr.transpose() @ X_centr)\n",
    "\n",
    "X_norm = X_centr @ (covariance / X.shape[0])**(-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "Path('../../data').mkdir(exist_ok=True, parents=True)\n",
    "trainset = datasets.MNIST(root='../../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "valset = datasets.MNIST(root='../../data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "60000"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([1, 28, 28])"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "trainset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=28x28 at 0x7FF741EEB0A0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "DataLoader(trainset).dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001b[0;31mInit signature:\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m     \nDataset wrapping tensors.\n\nEach sample will be retrieved by indexing tensors along the first dimension.\n\nArguments:\n    *tensors (Tensor): tensors that have the same size of the first dimension.\n\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py\n\u001b[0;31mType:\u001b[0m           type\n\u001b[0;31mSubclasses:\u001b[0m     \n"
    }
   ],
   "source": [
    "TensorDataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}